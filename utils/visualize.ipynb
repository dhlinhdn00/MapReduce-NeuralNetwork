{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SetUp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import psutil\n",
    "import threading\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "from PIL import Image, ImageOps, ImageChops\n",
    "import argparse\n",
    "import random\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "matplotlib.use('TkAgg') \n",
    "from matplotlib import gridspec\n",
    "from preprocess import preprocess, augment_image, add_gaussian_noise, apply_elastic_distortion\n",
    "from collections import Counter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "input_dir = \"/home/meos/Documents/MapReduceNeuralNetwork/data/1/mnist_png/\"\n",
    "output_dir = \"/home/meos/Documents/MapReduceNeuralNetwork/data/processed/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Original Data Visulization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_broken_files(data_dir):\n",
    "    broken_files = []\n",
    "    for root, dirs, files in os.walk(data_dir):\n",
    "        for filename in files:\n",
    "            if filename.endswith('.png'):\n",
    "                fpath = os.path.join(root, filename)\n",
    "                try:\n",
    "                    im = Image.open(fpath)\n",
    "                    im.verify() \n",
    "                except Exception:\n",
    "                    print(\"Broken or invalid image:\", fpath)\n",
    "                    broken_files.append(fpath)\n",
    "    print(broken_files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "check_broken_files(\"/home/meos/Documents/MapReduceNeuralNetwork/data/1/mnist_png/train\")\n",
    "check_broken_files(\"/home/meos/Documents/MapReduceNeuralNetwork/data/1/mnist_png/test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess(input_dir, output_dir, percent=100, augment=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "invalid command name \"133955808007168process_stream_events\"\n",
      "    while executing\n",
      "\"133955808007168process_stream_events\"\n",
      "    (\"after\" script)\n",
      "can't invoke \"event\" command: application has been destroyed\n",
      "    while executing\n",
      "\"event generate $w <<ThemeChanged>>\"\n",
      "    (procedure \"ttk::ThemeChanged\" line 6)\n",
      "    invoked from within\n",
      "\"ttk::ThemeChanged\"\n"
     ]
    }
   ],
   "source": [
    "# Single Test\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "image_path = \"/home/meos/Documents/MapReduceNeuralNetwork/data/1/mnist_png/train/0/59878.png\"\n",
    "\n",
    "image = Image.open(image_path).convert(\"L\")  \n",
    "image_array = np.array(image)\n",
    "\n",
    "plt.imshow(image_array, cmap=\"gray\")\n",
    "plt.title(\"Sample Image\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_from_text(file_path, num_samples=5):\n",
    "    \"\"\"\n",
    "    Load data from the processed text file.\n",
    "    Returns a list of tuples: (label, image_array)\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    with open(file_path, 'r') as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split()\n",
    "            label = int(parts[0])\n",
    "            pixels = np.array(list(map(float, parts[1:]))).reshape(28, 28)\n",
    "            data.append((label, pixels))\n",
    "            if len(data) >= num_samples:\n",
    "                break\n",
    "    return data\n",
    "\n",
    "def visualize_random_image(input_dir, subset='train', num_samples=5):\n",
    "    \"\"\"\n",
    "    Visualize randomly MNIST data from PNG images.\n",
    "    \n",
    "    Parameters:\n",
    "    - input_dir (str): Path to the MNIST PNG data directory.\n",
    "    - subset (str): 'train' or 'test'.\n",
    "    - num_samples (int): Number of samples to display.\n",
    "    \"\"\"\n",
    "    subset_dir = os.path.join(input_dir, subset)\n",
    "    if not os.path.isdir(subset_dir):\n",
    "        print(f\"Subset directory {subset_dir} does not exist.\", file=sys.stderr)\n",
    "        return\n",
    "    \n",
    "    fig, axes = plt.subplots(1, num_samples, figsize=(num_samples * 2, 2))\n",
    "    fig.suptitle(f\"Original MNIST {subset.capitalize()} Images\", fontsize=16)\n",
    "    \n",
    "    if num_samples == 1:\n",
    "        axes = [axes]\n",
    "    \n",
    "    for i in range(num_samples):\n",
    "        ax = axes[i]\n",
    "        \n",
    "        # Randomly select a label\n",
    "        label = random.randint(0, 9)\n",
    "        label_dir = os.path.join(subset_dir, str(label))\n",
    "        \n",
    "        if not os.path.isdir(label_dir):\n",
    "            print(f\"Directory {label_dir} does not exist. Skipping.\", file=sys.stderr)\n",
    "            ax.axis('off')\n",
    "            continue\n",
    "        \n",
    "        # List all PNG files in the label directory\n",
    "        files = [file for file in os.listdir(label_dir) if file.endswith('.png')]\n",
    "        \n",
    "        if not files:\n",
    "            print(f\"No PNG files in directory {label_dir}. Skipping.\", file=sys.stderr)\n",
    "            ax.axis('off')\n",
    "            continue\n",
    "        \n",
    "        # Randomly select a file\n",
    "        file = random.choice(files)\n",
    "        file_path = os.path.join(label_dir, file)\n",
    "        \n",
    "        try:\n",
    "            # Open and convert the image\n",
    "            image = Image.open(file_path).convert('L')\n",
    "            image = image.resize((28, 28), resample=Image.LANCZOS) \n",
    "            pixels = np.array(image)\n",
    "            \n",
    "            print(f\"Displaying image: {file_path}\")\n",
    "            print(f\"Pixels type: {type(pixels)}, shape: {pixels.shape}, dtype: {pixels.dtype}\")\n",
    "            \n",
    "            if not isinstance(pixels, np.ndarray):\n",
    "                raise ValueError(f\"Pixels is not a numpy array for file {file_path}\")\n",
    "            if pixels.shape != (28, 28):\n",
    "                raise ValueError(f\"Pixels shape is incorrect for file {file_path}: {pixels.shape}\")\n",
    "            \n",
    "            # Display the image\n",
    "            ax.imshow(pixels, cmap='gray', vmin=0, vmax=255)\n",
    "            ax.set_title(f\"Label: {label}\")\n",
    "            ax.axis('off')\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {file_path}: {e}\", file=sys.stderr)\n",
    "            ax.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def visualize_one_image_per_class(input_dir, subset='train'):\n",
    "    \"\"\"\n",
    "    Visualize one image for each class in the MNIST dataset.\n",
    "    \n",
    "    Parameters:\n",
    "    - input_dir (str): Path to the MNIST PNG data directory.\n",
    "    - subset (str): 'train' or 'test'.\n",
    "    \"\"\"\n",
    "    subset_dir = os.path.join(input_dir, subset)\n",
    "    if not os.path.isdir(subset_dir):\n",
    "        print(f\"Subset directory {subset_dir} does not exist.\", file=sys.stderr)\n",
    "        return\n",
    "    \n",
    "    num_classes = 10 \n",
    "    fig, axes = plt.subplots(1, num_classes, figsize=(num_classes * 2, 2))\n",
    "    fig.suptitle(f\"One Image Per Class - {subset.capitalize()} Dataset\", fontsize=16)\n",
    "    \n",
    "    for label in range(num_classes):\n",
    "        ax = axes[label]\n",
    "        label_dir = os.path.join(subset_dir, str(label))\n",
    "        \n",
    "        if not os.path.isdir(label_dir):\n",
    "            print(f\"Directory {label_dir} does not exist. Skipping class {label}.\", file=sys.stderr)\n",
    "            ax.axis('off')\n",
    "            continue\n",
    "        \n",
    "        # List all PNG files in the label directory\n",
    "        files = [file for file in os.listdir(label_dir) if file.endswith('.png')]\n",
    "        \n",
    "        if not files:\n",
    "            print(f\"No PNG files in directory {label_dir}. Skipping class {label}.\", file=sys.stderr)\n",
    "            ax.axis('off')\n",
    "            continue\n",
    "        \n",
    "        # Select the first file or a random file\n",
    "        file = files[0]  # First File\n",
    "        file_path = os.path.join(label_dir, file)\n",
    "        \n",
    "        try:\n",
    "            # Open and convert the image\n",
    "            image = Image.open(file_path).convert('L')\n",
    "            image = image.resize((28, 28), resample=Image.LANCZOS)\n",
    "            pixels = np.array(image)\n",
    "            \n",
    "            # Show\n",
    "            ax.imshow(pixels, cmap='gray', vmin=0, vmax=255)\n",
    "            ax.set_title(f\"Label: {label}\")\n",
    "            ax.axis('off')\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {file_path}: {e}\", file=sys.stderr)\n",
    "            ax.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def display_data_statistics(input_dir, subset='train', num_samples=None, show_plot=True):\n",
    "    \"\"\"\n",
    "    Display statistics about the dataset by loading data from a text file.\n",
    "    \n",
    "    Parameters:\n",
    "    - input_dir (str): Path to the directory containing MNIST text data.\n",
    "    - subset (str): 'train' or 'test' to specify which subset to analyze.\n",
    "    - num_samples (int): Optional. Limit the number of samples to load.\n",
    "    \"\"\"\n",
    "    file_path = os.path.join(input_dir, f\"mnist_{subset}.txt\")\n",
    "    \n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"File {file_path} does not exist.\", file=sys.stderr)\n",
    "        return\n",
    "\n",
    "    def load_data_from_text(file_path, num_samples=None):\n",
    "        \"\"\"\n",
    "        Load data from the processed text file.\n",
    "        Returns a list of tuples: (label, image_array)\n",
    "        \"\"\"\n",
    "        data = []\n",
    "        with open(file_path, 'r') as f:\n",
    "            for line in f:\n",
    "                parts = line.strip().split()\n",
    "                label = int(parts[0])\n",
    "                pixels = np.array(list(map(float, parts[1:]))).reshape(28, 28)\n",
    "                data.append((label, pixels))\n",
    "                if num_samples and len(data) >= num_samples:\n",
    "                    break\n",
    "        return data\n",
    "\n",
    "    data = load_data_from_text(file_path, num_samples)\n",
    "\n",
    "    total_samples = len(data)\n",
    "    labels = [item[0] for item in data]\n",
    "    label_counts = Counter(labels)\n",
    "    \n",
    "    print(f\"Total: {total_samples}\")\n",
    "    print(\"Class:\")\n",
    "    for label in sorted(label_counts.keys()):\n",
    "        print(f\"  Label {label}: {label_counts[label]} samples\")\n",
    "    \n",
    "    if show_plot:\n",
    "        labels = sorted(label_counts.keys())\n",
    "        counts = [label_counts[label] for label in labels]\n",
    "        \n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.bar(labels, counts, color='skyblue')\n",
    "        plt.title(f\"Class Distribution in {subset.capitalize()} Dataset\", fontsize=16)\n",
    "        plt.xlabel(\"Class Labels\", fontsize=14)\n",
    "        plt.ylabel(\"Number of Samples\", fontsize=14)\n",
    "        plt.xticks(labels, fontsize=12)\n",
    "        plt.yticks(fontsize=12)\n",
    "        plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "def visualize_augmentations(image_path):\n",
    "    \"\"\"\n",
    "    Visualize the different augmentations applied to an image.\n",
    "    \n",
    "    Parameters:\n",
    "    - image_path (str): Path to the original image file.\n",
    "    \"\"\"\n",
    "    # Load the original image\n",
    "    original_image = Image.open(image_path).convert('L').resize((28, 28))\n",
    "    \n",
    "    augmentations = {\n",
    "        \"Original\": lambda img: img,\n",
    "        \"Rotation\": lambda img: img.rotate(random.uniform(-20, 20), fillcolor=0),\n",
    "        \"Shift\": lambda img: ImageChops.offset(img, random.randint(-3, 3), random.randint(-3, 3)),\n",
    "        \"Scaling\": lambda img: ImageOps.fit(\n",
    "            img.resize(\n",
    "                (int(28 * random.uniform(0.9, 1.1)), int(28 * random.uniform(0.9, 1.1))), \n",
    "                Image.LANCZOS\n",
    "            ), (28, 28), Image.LANCZOS\n",
    "        ),\n",
    "        \"Shearing\": lambda img: img.transform(\n",
    "            img.size, Image.AFFINE, \n",
    "            (1, random.uniform(-0.1, 0.1), 0, 0, 1, 0), Image.BICUBIC, fillcolor=0\n",
    "        ),\n",
    "        \"Elastic Distortion\": lambda img: apply_elastic_distortion(img),\n",
    "        \"Gaussian Noise\": lambda img: add_gaussian_noise(img)\n",
    "    }\n",
    "\n",
    "    # Visualize each augmentation\n",
    "    num_augmentations = len(augmentations)\n",
    "    fig, axes = plt.subplots(2, num_augmentations, figsize=(num_augmentations * 2, 4))\n",
    "    fig.suptitle(\"Visualizing Augmentations\", fontsize=16)\n",
    "    \n",
    "    for i, (name, augment_func) in enumerate(augmentations.items()):\n",
    "        # Apply augmentation twice\n",
    "        for j in range(2):\n",
    "            ax = axes[j, i]\n",
    "            try:\n",
    "                augmented_image = augment_func(original_image)\n",
    "                ax.imshow(np.array(augmented_image), cmap='gray', vmin=0, vmax=255)\n",
    "                if j == 0:\n",
    "                    ax.set_title(name, fontsize=10)\n",
    "                ax.axis('off')\n",
    "            except Exception as e:\n",
    "                print(f\"Error applying {name} augmentation: {e}\", file=sys.stderr)\n",
    "                ax.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(top=0.85)\n",
    "    plt.show()\n",
    "\n",
    "def visualize_augmentations_per_class(input_dir, subset='train'):\n",
    "    \"\"\"\n",
    "    Visualize all augmentations applied to a sample image from each class (0-9).\n",
    "    \n",
    "    Parameters:\n",
    "    - input_dir (str): Path to the MNIST PNG data directory.\n",
    "    - subset (str): 'train' or 'test'.\n",
    "    \"\"\"\n",
    "    subset_dir = os.path.join(input_dir, subset)\n",
    "    if not os.path.isdir(subset_dir):\n",
    "        print(f\"Subset directory {subset_dir} does not exist.\", file=sys.stderr)\n",
    "        return\n",
    "\n",
    "    # Define augmentations\n",
    "    augmentations = {\n",
    "        \"Original\": lambda img: img,\n",
    "        \"Rotation\": lambda img: img.rotate(random.uniform(-20, 20), fillcolor=0),\n",
    "        \"Shift\": lambda img: ImageChops.offset(img, random.randint(-3, 3), random.randint(-3, 3)),\n",
    "        \"Scaling\": lambda img: ImageOps.fit(\n",
    "            img.resize(\n",
    "                (int(28 * random.uniform(0.9, 1.1)), int(28 * random.uniform(0.9, 1.1))), \n",
    "                Image.LANCZOS\n",
    "            ), (28, 28), Image.LANCZOS\n",
    "        ),\n",
    "        \"Shearing\": lambda img: img.transform(\n",
    "            img.size, Image.AFFINE, \n",
    "            (1, random.uniform(-0.1, 0.1), 0, 0, 1, 0), Image.BICUBIC, fillcolor=0\n",
    "        ),\n",
    "        \"Elastic Distortion\": lambda img: apply_elastic_distortion(img),\n",
    "        \"Gaussian Noise\": lambda img: add_gaussian_noise(img)\n",
    "    }\n",
    "\n",
    "    num_classes = 10  # Hiển thị 10 lớp\n",
    "    num_augmentations = len(augmentations)\n",
    "\n",
    "    # Create a figure\n",
    "    fig, axes = plt.subplots(num_classes, num_augmentations, figsize=(num_augmentations * 3, num_classes * 3))\n",
    "    fig.suptitle(f\"Visualizing Augmentations for Classes 0-{num_classes - 1} ({subset.capitalize()})\", fontsize=16)\n",
    "    \n",
    "    for label in range(num_classes):\n",
    "        label_dir = os.path.join(subset_dir, str(label))\n",
    "        if not os.path.isdir(label_dir):\n",
    "            print(f\"Directory for class {label} does not exist. Skipping.\", file=sys.stderr)\n",
    "            continue\n",
    "        \n",
    "        # List all PNG files in the label directory\n",
    "        files = [file for file in os.listdir(label_dir) if file.endswith('.png')]\n",
    "        if not files:\n",
    "            print(f\"No PNG files in directory for class {label}. Skipping.\", file=sys.stderr)\n",
    "            continue\n",
    "\n",
    "        # Select the first file for this label\n",
    "        file_path = os.path.join(label_dir, files[0])\n",
    "        try:\n",
    "            original_image = Image.open(file_path).convert('L').resize((28, 28))\n",
    "            \n",
    "            for i, (name, augment_func) in enumerate(augmentations.items()):\n",
    "                ax = axes[label, i]\n",
    "                try:\n",
    "                    augmented_image = augment_func(original_image)\n",
    "                    ax.imshow(np.array(augmented_image), cmap='gray', vmin=0, vmax=255)\n",
    "                    if label == 0:\n",
    "                        ax.set_title(name, fontsize=10)\n",
    "                    ax.axis('off')\n",
    "                except Exception as e:\n",
    "                    print(f\"Error applying {name} augmentation to class {label}: {e}\", file=sys.stderr)\n",
    "                    ax.axis('off')\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing image for class {label}: {e}\", file=sys.stderr)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(top=0.92)\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying image: /home/meos/Documents/MapReduceNeuralNetwork/data/1/mnist_png/train/1/41723.png\n",
      "Pixels type: <class 'numpy.ndarray'>, shape: (28, 28), dtype: uint8\n",
      "Displaying image: /home/meos/Documents/MapReduceNeuralNetwork/data/1/mnist_png/train/4/34780.png\n",
      "Pixels type: <class 'numpy.ndarray'>, shape: (28, 28), dtype: uint8\n",
      "Displaying image: /home/meos/Documents/MapReduceNeuralNetwork/data/1/mnist_png/train/3/25553.png\n",
      "Pixels type: <class 'numpy.ndarray'>, shape: (28, 28), dtype: uint8\n",
      "Displaying image: /home/meos/Documents/MapReduceNeuralNetwork/data/1/mnist_png/train/1/49113.png\n",
      "Pixels type: <class 'numpy.ndarray'>, shape: (28, 28), dtype: uint8\n",
      "Displaying image: /home/meos/Documents/MapReduceNeuralNetwork/data/1/mnist_png/train/8/45116.png\n",
      "Pixels type: <class 'numpy.ndarray'>, shape: (28, 28), dtype: uint8\n",
      "Displaying image: /home/meos/Documents/MapReduceNeuralNetwork/data/1/mnist_png/train/9/10410.png\n",
      "Pixels type: <class 'numpy.ndarray'>, shape: (28, 28), dtype: uint8\n",
      "Displaying image: /home/meos/Documents/MapReduceNeuralNetwork/data/1/mnist_png/train/0/39960.png\n",
      "Pixels type: <class 'numpy.ndarray'>, shape: (28, 28), dtype: uint8\n",
      "Displaying image: /home/meos/Documents/MapReduceNeuralNetwork/data/1/mnist_png/train/1/45598.png\n",
      "Pixels type: <class 'numpy.ndarray'>, shape: (28, 28), dtype: uint8\n",
      "Displaying image: /home/meos/Documents/MapReduceNeuralNetwork/data/1/mnist_png/train/3/19307.png\n",
      "Pixels type: <class 'numpy.ndarray'>, shape: (28, 28), dtype: uint8\n",
      "Displaying image: /home/meos/Documents/MapReduceNeuralNetwork/data/1/mnist_png/train/9/50228.png\n",
      "Pixels type: <class 'numpy.ndarray'>, shape: (28, 28), dtype: uint8\n"
     ]
    }
   ],
   "source": [
    "visualize_random_image(input_dir, subset='train', num_samples=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_one_image_per_class(input_dir, subset='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total: 240000\n",
      "Class:\n",
      "  Label 0: 23692 samples\n",
      "  Label 1: 26968 samples\n",
      "  Label 2: 23832 samples\n",
      "  Label 3: 24524 samples\n",
      "  Label 4: 23368 samples\n",
      "  Label 5: 21684 samples\n",
      "  Label 6: 23672 samples\n",
      "  Label 7: 25060 samples\n",
      "  Label 8: 23404 samples\n",
      "  Label 9: 23796 samples\n"
     ]
    }
   ],
   "source": [
    "display_data_statistics(output_dir, subset='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total: 40000\n",
      "Class:\n",
      "  Label 0: 3920 samples\n",
      "  Label 1: 4540 samples\n",
      "  Label 2: 4128 samples\n",
      "  Label 3: 4040 samples\n",
      "  Label 4: 3928 samples\n",
      "  Label 5: 3568 samples\n",
      "  Label 6: 3832 samples\n",
      "  Label 7: 4112 samples\n",
      "  Label 8: 3896 samples\n",
      "  Label 9: 4036 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "invalid command name \"133954640013504process_stream_events\"\n",
      "    while executing\n",
      "\"133954640013504process_stream_events\"\n",
      "    (\"after\" script)\n",
      "can't invoke \"event\" command: application has been destroyed\n",
      "    while executing\n",
      "\"event generate $w <<ThemeChanged>>\"\n",
      "    (procedure \"ttk::ThemeChanged\" line 6)\n",
      "    invoked from within\n",
      "\"ttk::ThemeChanged\"\n"
     ]
    }
   ],
   "source": [
    "display_data_statistics(output_dir, subset='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_augmentations(\"/home/meos/Documents/MapReduceNeuralNetwork/data/1/mnist_png/test/9/16.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_augmentations_per_class(input_dir, subset='train')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Monitor Performance Tracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def monitor_performance(func, *args, **kwargs):\n",
    "    \"\"\"\n",
    "    Monitors the performance of a function, capturing execution time and resource usage.\n",
    "    \"\"\"\n",
    "    process = psutil.Process(os.getpid())\n",
    "    \n",
    "    # Record initial CPU and memory usage\n",
    "    cpu_before = process.cpu_percent(interval=None)\n",
    "    mem_before = process.memory_info().rss  # in bytes\n",
    "    \n",
    "    # Record start time\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Execute the function\n",
    "    func(*args, **kwargs)\n",
    "    \n",
    "    # Record end time\n",
    "    end_time = time.time()\n",
    "    \n",
    "    # Record final CPU and memory usage\n",
    "    cpu_after = process.cpu_percent(interval=None)\n",
    "    mem_after = process.memory_info().rss  # in bytes\n",
    "    \n",
    "    # Calculate metrics\n",
    "    cpu_usage = cpu_after - cpu_before  # CPU usage percentage\n",
    "    mem_usage = (mem_after - mem_before) / (1024 ** 2)  # Memory usage in MB\n",
    "    elapsed_time = end_time - start_time  # Time in seconds\n",
    "    \n",
    "    print(f\"Function '{func.__name__}' executed in {elapsed_time:.2f} seconds\")\n",
    "    print(f\"CPU Usage: {cpu_usage:.2f}%\")\n",
    "    print(f\"Memory Usage: {mem_usage:.2f} MB\")\n",
    "\n",
    "def monitor_resources(interval=1, cpu_usage_list=None, mem_usage_list=None):\n",
    "    \"\"\"\n",
    "    Continuously monitors CPU and memory usage at specified intervals.    \n",
    "    Parameters:\n",
    "    - interval (int)\n",
    "    - cpu_usage_list (list)\n",
    "    - mem_usage_list (list)\n",
    "    \"\"\"\n",
    "    process = psutil.Process(os.getpid())\n",
    "    while True:\n",
    "        cpu = process.cpu_percent(interval=interval)\n",
    "        mem = process.memory_info().rss / (1024 ** 2)  # Convert to MB\n",
    "        if cpu_usage_list is not None and mem_usage_list is not None:\n",
    "            cpu_usage_list.append(cpu)\n",
    "            mem_usage_list.append(mem)\n",
    "        # print(f\"CPU Usage: {cpu}% | Memory Usage: {mem} MB\")\n",
    "\n",
    "def monitor_performance_with_continuous_tracking(func, *args, **kwargs):\n",
    "    cpu_usage_list = []\n",
    "    mem_usage_list = []\n",
    "    \n",
    "    monitor_thread = threading.Thread(\n",
    "        target=monitor_resources, \n",
    "        args=(1, cpu_usage_list, mem_usage_list), \n",
    "        daemon=True\n",
    "    )\n",
    "    monitor_thread.start()\n",
    "    start_time = time.time()\n",
    "    func(*args, **kwargs)\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    \n",
    "    if cpu_usage_list:\n",
    "        cpu_average = sum(cpu_usage_list) / len(cpu_usage_list)\n",
    "        cpu_peak = max(cpu_usage_list)\n",
    "    else:\n",
    "        cpu_average = 0\n",
    "        cpu_peak = 0\n",
    "    \n",
    "    if mem_usage_list:\n",
    "        mem_peak = max(mem_usage_list)\n",
    "    else:\n",
    "        mem_peak = 0\n",
    "    \n",
    "    print(f\"\\nFunction '{func.__name__}' executed in {elapsed_time:.2f} seconds\")\n",
    "    print(f\"CPU Usage: Average = {cpu_average:.2f}% | Highest = {cpu_peak:.2f}%\")\n",
    "    print(f\"Memory Usage: Highest = {mem_peak:.2f} MB\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmonitor_performance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpreprocess\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpercent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maugment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[22], line 15\u001b[0m, in \u001b[0;36mmonitor_performance\u001b[0;34m(func, *args, **kwargs)\u001b[0m\n\u001b[1;32m     12\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Execute the function\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Record end time\u001b[39;00m\n\u001b[1;32m     18\u001b[0m end_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n",
      "File \u001b[0;32m~/Documents/MapReduceNeuralNetwork/utils/preprocess.py:52\u001b[0m, in \u001b[0;36mpreprocess\u001b[0;34m(input_dir, output_dir, percent, augment)\u001b[0m\n\u001b[1;32m     49\u001b[0m out_f\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabel_int\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpixels_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# Write label and pixel values to output file\u001b[39;00m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m augment:\n\u001b[0;32m---> 52\u001b[0m     augmented_images \u001b[38;5;241m=\u001b[39m \u001b[43maugment_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     53\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m aug_image \u001b[38;5;129;01min\u001b[39;00m augmented_images:\n\u001b[1;32m     54\u001b[0m         aug_pixels \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(aug_image)\u001b[38;5;241m.\u001b[39mflatten() \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m255.0\u001b[39m\n",
      "File \u001b[0;32m~/Documents/MapReduceNeuralNetwork/utils/preprocess.py:100\u001b[0m, in \u001b[0;36maugment_image\u001b[0;34m(image)\u001b[0m\n\u001b[1;32m     91\u001b[0m aug_image \u001b[38;5;241m=\u001b[39m aug_image\u001b[38;5;241m.\u001b[39mtransform(\n\u001b[1;32m     92\u001b[0m     aug_image\u001b[38;5;241m.\u001b[39msize,\n\u001b[1;32m     93\u001b[0m     Image\u001b[38;5;241m.\u001b[39mAFFINE,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     96\u001b[0m     fillcolor\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     97\u001b[0m )\n\u001b[1;32m     99\u001b[0m \u001b[38;5;66;03m# Apply elastic distortion\u001b[39;00m\n\u001b[0;32m--> 100\u001b[0m aug_image \u001b[38;5;241m=\u001b[39m \u001b[43mapply_elastic_distortion\u001b[49m\u001b[43m(\u001b[49m\u001b[43maug_image\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;66;03m# Add Gaussian noise\u001b[39;00m\n\u001b[1;32m    103\u001b[0m aug_image \u001b[38;5;241m=\u001b[39m add_gaussian_noise(aug_image)\n",
      "File \u001b[0;32m~/Documents/MapReduceNeuralNetwork/utils/preprocess.py:138\u001b[0m, in \u001b[0;36mapply_elastic_distortion\u001b[0;34m(image, alpha, sigma)\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;66;03m# Map coordinates to the image\u001b[39;00m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mndimage\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m map_coordinates\n\u001b[0;32m--> 138\u001b[0m distorted_image \u001b[38;5;241m=\u001b[39m \u001b[43mmap_coordinates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp_image\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mreflect\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Image\u001b[38;5;241m.\u001b[39mfromarray(distorted_image\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39muint8))\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/scipy/ndimage/_interpolation.py:442\u001b[0m, in \u001b[0;36mmap_coordinates\u001b[0;34m(input, coordinates, output, order, mode, cval, prefilter)\u001b[0m\n\u001b[1;32m    440\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minvalid shape for coordinate array\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    441\u001b[0m complex_output \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39miscomplexobj(\u001b[38;5;28minput\u001b[39m)\n\u001b[0;32m--> 442\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43m_ni_support\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_output\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_shape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    443\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mcomplex_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcomplex_output\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    444\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m complex_output:\n\u001b[1;32m    445\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(order\u001b[38;5;241m=\u001b[39morder, mode\u001b[38;5;241m=\u001b[39mmode, prefilter\u001b[38;5;241m=\u001b[39mprefilter)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/scipy/ndimage/_ni_support.py:79\u001b[0m, in \u001b[0;36m_get_output\u001b[0;34m(output, input, shape, complex_output)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m complex_output:\n\u001b[0;32m---> 79\u001b[0m         output \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39mzeros(shape, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m)\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     81\u001b[0m         complex_type \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39mpromote_types(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mdtype, numpy\u001b[38;5;241m.\u001b[39mcomplex64)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/numpy/core/_dtype.py:363\u001b[0m, in \u001b[0;36m_name_get\u001b[0;34m(dtype)\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[38;5;66;03m# append bit counts\u001b[39;00m\n\u001b[1;32m    362\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _name_includes_bit_suffix(dtype):\n\u001b[0;32m--> 363\u001b[0m     name \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitemsize\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    365\u001b[0m \u001b[38;5;66;03m# append metadata to datetimes\u001b[39;00m\n\u001b[1;32m    366\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype\u001b[38;5;241m.\u001b[39mtype \u001b[38;5;129;01min\u001b[39;00m (np\u001b[38;5;241m.\u001b[39mdatetime64, np\u001b[38;5;241m.\u001b[39mtimedelta64):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "monitor_performance(preprocess, input_dir, output_dir, percent=100, augment=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Function 'preprocess' executed in 206.61 seconds\n",
      "CPU Usage: Average = 73.43% | Highest = 100.90%\n",
      "Memory Usage: Highest = 2271.71 MB\n"
     ]
    }
   ],
   "source": [
    "monitor_performance_with_continuous_tracking(preprocess, input_dir, output_dir, percent=100, augment=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
